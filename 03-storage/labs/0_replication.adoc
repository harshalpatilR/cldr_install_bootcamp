....
== find terasort location
[root@harshalinstalllab-5 ~]# find / -name "hadoop-*examples*.jar"
/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hue/apps/oozie/examples/lib/hadoop-examples.jar
/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-mapreduce/hadoop-mapreduce-examples-2.6.0-cdh5.15.2.jar
/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar
/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-0.20-mapreduce/hadoop-examples-mr1.jar
/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-0.20-mapreduce/hadoop-examples.jar
/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-0.20-mapreduce/hadoop-examples-2.6.0-mr1-cdh5.15.2.jar
/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/share/doc/hadoop-0.20-mapreduce/examples/hadoop-examples.jar
/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/share/doc/hadoop-0.20-mapreduce/examples/hadoop-examples-2.6.0-mr1-cdh5.15.2.jar
/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/jars/hadoop-examples.jar
/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/jars/hadoop-mapreduce-examples-2.6.0-cdh5.15.2.jar
/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/jars/hadoop-examples-2.6.0-mr1-cdh5.15.2.jar


== hdfs make directory
[root@harshalinstalllab-5 ~]# su hdfs
[hdfs@harshalinstalllab-5 root]$ hdfs dfs mkdir /usr
mkdir: Unknown command
Did you mean -mkdir?  This command begins with a dash.
[hdfs@harshalinstalllab-5 root]$ hdfs dfs -mkdir /usr
[hdfs@harshalinstalllab-5 root]$ hdfs dfs -mkdir /usr/harshal
[hdfs@harshalinstalllab-5 root]$ hdfs dfs -ls /usr/harshal


== terasort to generate data
[root@harshalinstalllab-5 ~]# su hdfs
[hdfs@harshalinstalllab-5 root]$ hadoop jar
RunJar jarFile [mainClass] args...
[hdfs@harshalinstalllab-5 root]$ hadoop jar /opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar teragen 5000000 /usr/harshal
java.io.IOException: Output directory /usr/harshal already exists.
	at org.apache.hadoop.examples.terasort.TeraGen.run(TeraGen.java:293)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.hadoop.examples.terasort.TeraGen.main(TeraGen.java:309)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)
	at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)
	at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:226)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:141)
[hdfs@harshalinstalllab-5 root]$ hadoop jar /opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar teragen 5000000 /usr/harshal/.
java.io.IOException: Output directory /usr/harshal/ already exists.
	at org.apache.hadoop.examples.terasort.TeraGen.run(TeraGen.java:293)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.hadoop.examples.terasort.TeraGen.main(TeraGen.java:309)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)
	at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)
	at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:226)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:141)
[hdfs@harshalinstalllab-5 root]$ hdfs dfs -rm /usr/harshal
rm: `/usr/harshal': Is a directory
[hdfs@harshalinstalllab-5 root]$ hdfs dfs -rmdir /usr/harshal
[hdfs@harshalinstalllab-5 root]$ hadoop jar /opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar teragen 5000000 /usr/harshal/.
19/12/03 10:18:54 INFO client.RMProxy: Connecting to ResourceManager at harshalinstalllab-1.gce.cloudera.com/172.31.116.204:8032
19/12/03 10:18:55 INFO terasort.TeraGen: Generating 5000000 using 2
19/12/03 10:18:55 INFO mapreduce.JobSubmitter: number of splits:2
19/12/03 10:18:56 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1575336507718_0001
19/12/03 10:18:57 INFO impl.YarnClientImpl: Submitted application application_1575336507718_0001
19/12/03 10:18:57 INFO mapreduce.Job: The url to track the job: http://harshalinstalllab-1.gce.cloudera.com:8088/proxy/application_1575336507718_0001/
19/12/03 10:18:57 INFO mapreduce.Job: Running job: job_1575336507718_0001
19/12/03 10:19:04 INFO mapreduce.Job: Job job_1575336507718_0001 running in uber mode : false
19/12/03 10:19:04 INFO mapreduce.Job:  map 0% reduce 0%
19/12/03 10:19:22 INFO mapreduce.Job:  map 100% reduce 0%
19/12/03 10:19:23 INFO mapreduce.Job: Job job_1575336507718_0001 completed successfully
19/12/03 10:19:23 INFO mapreduce.Job: Counters: 31
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=298724
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=167
		HDFS: Number of bytes written=500000000
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Job Counters 
		Launched map tasks=2
		Other local map tasks=2
		Total time spent by all maps in occupied slots (ms)=31060
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=31060
		Total vcore-milliseconds taken by all map tasks=31060
		Total megabyte-milliseconds taken by all map tasks=31805440
	Map-Reduce Framework
		Map input records=5000000
		Map output records=5000000
		Input split bytes=167
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=598
		CPU time spent (ms)=13350
		Physical memory (bytes) snapshot=721825792
		Virtual memory (bytes) snapshot=5556473856
		Total committed heap usage (bytes)=698351616
	org.apache.hadoop.examples.terasort.TeraGen$Counters
		CHECKSUM=10735710707299981
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=500000000
[hdfs@harshalinstalllab-5 root]$ hdfs dfs -ls /usr/harshal
Found 3 items
-rw-r--r--   3 hdfs supergroup          0 2019-12-03 10:19 /usr/harshal/_SUCCESS
-rw-r--r--   3 hdfs supergroup  250000000 2019-12-03 10:19 /usr/harshal/part-m-00000
-rw-r--r--   3 hdfs supergroup  250000000 2019-12-03 10:19 /usr/harshal/part-m-00001
[hdfs@harshalinstalllab-5 root]$ hadoop jar /opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar teragen 5000000 /usr/harshal/.
java.io.IOException: Output directory /usr/harshal/ already exists.
	at org.apache.hadoop.examples.terasort.TeraGen.run(TeraGen.java:293)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.hadoop.examples.terasort.TeraGen.main(TeraGen.java:309)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)
	at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)
	at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:226)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:141)
[hdfs@harshalinstalllab-5 root]$ hdfs dfs -ls /usr/harshal
Found 3 items
-rw-r--r--   3 hdfs supergroup          0 2019-12-03 10:19 /usr/harshal/_SUCCESS
-rw-r--r--   3 hdfs supergroup  250000000 2019-12-03 10:19 /usr/harshal/part-m-00000
-rw-r--r--   3 hdfs supergroup  250000000 2019-12-03 10:19 /usr/harshal/part-m-00001
[hdfs@harshalinstalllab-5 root]$ hdfs dfs -rmdir /usr/harshal/.
rmdir: `/usr/harshal': Directory is not empty
[hdfs@harshalinstalllab-5 root]$ hdfs dfs -rm /usr/harshal/*
19/12/03 10:24:54 INFO fs.TrashPolicyDefault: Moved: 'hdfs://harshalinstalllab-1.gce.cloudera.com:8020/usr/harshal/_SUCCESS' to trash at: hdfs://harshalinstalllab-1.gce.cloudera.com:8020/user/hdfs/.Trash/Current/usr/harshal/_SUCCESS
19/12/03 10:24:54 INFO fs.TrashPolicyDefault: Moved: 'hdfs://harshalinstalllab-1.gce.cloudera.com:8020/usr/harshal/part-m-00000' to trash at: hdfs://harshalinstalllab-1.gce.cloudera.com:8020/user/hdfs/.Trash/Current/usr/harshal/part-m-00000
19/12/03 10:24:54 INFO fs.TrashPolicyDefault: Moved: 'hdfs://harshalinstalllab-1.gce.cloudera.com:8020/usr/harshal/part-m-00001' to trash at: hdfs://harshalinstalllab-1.gce.cloudera.com:8020/user/hdfs/.Trash/Current/usr/harshal/part-m-00001
[hdfs@harshalinstalllab-5 root]$ hdfs dfs -rmdir /usr/harshal/
[hdfs@harshalinstalllab-5 root]$ ls
ls: cannot open directory .: Permission denied
[hdfs@harshalinstalllab-5 root]$ hadoop jar /opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar teragen 5000000 /usr/harshal/.
19/12/03 10:25:32 INFO client.RMProxy: Connecting to ResourceManager at harshalinstalllab-1.gce.cloudera.com/172.31.116.204:8032
19/12/03 10:25:34 INFO terasort.TeraGen: Generating 5000000 using 2
19/12/03 10:25:34 INFO mapreduce.JobSubmitter: number of splits:2
19/12/03 10:25:34 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1575336507718_0002
19/12/03 10:25:34 INFO impl.YarnClientImpl: Submitted application application_1575336507718_0002
19/12/03 10:25:34 INFO mapreduce.Job: The url to track the job: http://harshalinstalllab-1.gce.cloudera.com:8088/proxy/application_1575336507718_0002/
19/12/03 10:25:34 INFO mapreduce.Job: Running job: job_1575336507718_0002
19/12/03 10:25:42 INFO mapreduce.Job: Job job_1575336507718_0002 running in uber mode : false
19/12/03 10:25:42 INFO mapreduce.Job:  map 0% reduce 0%
19/12/03 10:25:54 INFO mapreduce.Job:  map 50% reduce 0%
19/12/03 10:25:56 INFO mapreduce.Job:  map 100% reduce 0%
19/12/03 10:25:56 INFO mapreduce.Job: Job job_1575336507718_0002 completed successfully
19/12/03 10:25:56 INFO mapreduce.Job: Counters: 31
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=298724
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=167
		HDFS: Number of bytes written=500000000
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Job Counters 
		Launched map tasks=2
		Other local map tasks=2
		Total time spent by all maps in occupied slots (ms)=20278
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=20278
		Total vcore-milliseconds taken by all map tasks=20278
		Total megabyte-milliseconds taken by all map tasks=20764672
	Map-Reduce Framework
		Map input records=5000000
		Map output records=5000000
		Input split bytes=167
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=488
		CPU time spent (ms)=11620
		Physical memory (bytes) snapshot=657104896
		Virtual memory (bytes) snapshot=5557489664
		Total committed heap usage (bytes)=692584448
	org.apache.hadoop.examples.terasort.TeraGen$Counters
		CHECKSUM=10735710707299981
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=500000000
[hdfs@harshalinstalllab-5 root]$ hdfs dfs -ls /usr/harshal
Found 3 items
-rw-r--r--   3 hdfs supergroup          0 2019-12-03 10:25 /usr/harshal/_SUCCESS
-rw-r--r--   3 hdfs supergroup  250000000 2019-12-03 10:25 /usr/harshal/part-m-00000
-rw-r--r--   3 hdfs supergroup  250000000 2019-12-03 10:25 /usr/harshal/part-m-00001

== distcp to copy from remote
[hdfs@harshalinstalllab-5 root]$ hadoop distcp hdfs://luciano-bootcamp-2.gce.cloudera.com:8020/tmp/luciano hdfs://harshalinstalllab-1.gce.cloudera.com:8020/usr/luciano
19/12/03 10:40:10 INFO tools.OptionsParser: parseChunkSize: blocksperchunk false
19/12/03 10:40:11 INFO tools.DistCp: Input Options: DistCpOptions{atomicCommit=false, syncFolder=false, deleteMissing=false, ignoreFailures=false, overwrite=false, append=false, useDiff=false, useRdiff=false, fromSnapshot=null, toSnapshot=null, skipCRC=false, blocking=true, numListstatusThreads=0, maxMaps=20, mapBandwidth=100, sslConfigurationFile='null', copyStrategy='uniformsize', preserveStatus=[], preserveRawXattrs=false, atomicWorkPath=null, logPath=null, sourceFileListing=null, sourcePaths=[hdfs://luciano-bootcamp-2.gce.cloudera.com:8020/tmp/luciano], targetPath=hdfs://harshalinstalllab-1.gce.cloudera.com:8020/usr/luciano, targetPathExists=false, filtersFile='null', blocksPerChunk=0, copyBufferSize=8192}
19/12/03 10:40:11 INFO client.RMProxy: Connecting to ResourceManager at harshalinstalllab-1.gce.cloudera.com/172.31.116.204:8032
19/12/03 10:40:12 INFO tools.SimpleCopyListing: Paths (files+dirs) cnt = 4; dirCnt = 1
19/12/03 10:40:12 INFO tools.SimpleCopyListing: Build file listing completed.
19/12/03 10:40:12 INFO Configuration.deprecation: io.sort.mb is deprecated. Instead, use mapreduce.task.io.sort.mb
19/12/03 10:40:12 INFO Configuration.deprecation: io.sort.factor is deprecated. Instead, use mapreduce.task.io.sort.factor
19/12/03 10:40:12 INFO tools.DistCp: Number of paths in the copy list: 4
19/12/03 10:40:12 INFO tools.DistCp: Number of paths in the copy list: 4
19/12/03 10:40:12 INFO client.RMProxy: Connecting to ResourceManager at harshalinstalllab-1.gce.cloudera.com/172.31.116.204:8032
19/12/03 10:40:13 INFO mapreduce.JobSubmitter: number of splits:4
19/12/03 10:40:13 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1575336507718_0003
19/12/03 10:40:13 INFO impl.YarnClientImpl: Submitted application application_1575336507718_0003
19/12/03 10:40:13 INFO mapreduce.Job: The url to track the job: http://harshalinstalllab-1.gce.cloudera.com:8088/proxy/application_1575336507718_0003/
19/12/03 10:40:13 INFO tools.DistCp: DistCp job-id: job_1575336507718_0003
19/12/03 10:40:13 INFO mapreduce.Job: Running job: job_1575336507718_0003
19/12/03 10:40:21 INFO mapreduce.Job: Job job_1575336507718_0003 running in uber mode : false
19/12/03 10:40:21 INFO mapreduce.Job:  map 0% reduce 0%
19/12/03 10:40:27 INFO mapreduce.Job:  map 50% reduce 0%
19/12/03 10:40:34 INFO mapreduce.Job:  map 75% reduce 0%
19/12/03 10:40:35 INFO mapreduce.Job:  map 100% reduce 0%
19/12/03 10:40:35 INFO mapreduce.Job: Job job_1575336507718_0003 completed successfully
19/12/03 10:40:35 INFO mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=611692
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=524290181
		HDFS: Number of bytes written=524288000
		HDFS: Number of read operations=58
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=15
	Job Counters 
		Launched map tasks=4
		Other local map tasks=4
		Total time spent by all maps in occupied slots (ms)=29828
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=29828
		Total vcore-milliseconds taken by all map tasks=29828
		Total megabyte-milliseconds taken by all map tasks=30543872
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Input split bytes=460
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=641
		CPU time spent (ms)=8090
		Physical memory (bytes) snapshot=957362176
		Virtual memory (bytes) snapshot=11129589760
		Total committed heap usage (bytes)=990904320
	File Input Format Counters 
		Bytes Read=1721
	File Output Format Counters 
		Bytes Written=0
	DistCp Counters
		Bytes Copied=524288000
		Bytes Expected=524288000
		Files Copied=4
[hdfs@harshalinstalllab-5 root]$ hdfs dfs -ls /usr/luciano
Found 3 items
-rw-r--r--   3 hdfs supergroup          0 2019-12-03 10:40 /usr/luciano/_SUCCESS
-rw-r--r--   3 hdfs supergroup  262144000 2019-12-03 10:40 /usr/luciano/part-m-00000
-rw-r--r--   3 hdfs supergroup  262144000 2019-12-03 10:40 /usr/luciano/part-m-00001
[hdfs@harshalinstalllab-5 root]$ 

 
